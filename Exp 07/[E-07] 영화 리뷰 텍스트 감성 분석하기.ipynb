{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "three-portal",
   "metadata": {},
   "source": [
    "# 7-1. 들어가며\n",
    "\n",
    "안녕하세요 여러분,\n",
    "\n",
    "매일 새로운 주제를 공부해 나가시는 건 어떠신가요? 어떤 분에게는 벅찰 수도 있고, 어떤 분에게는 즐거움의 연속일 수 있습니다. 그렇지만 이렇게 짧은 시간 동안 다양한 도메인에 대해 학습을 하는 경험은 쉽지 않으니 조금만 더 힘을 내서 따라와 주시면 좋겠습니다.\n",
    "\n",
    "오늘은 자연어 처리에 주로 활용되는 RNN(Recurrent Neural Network)에 대해 배워볼 예정입니다. 그리고 컴퓨터 비전에서만 사용되는 줄 알았던 CNN(Convolutional Neural Network)이 자연어 처리에서 사용될 수도 있다는 것을 알게 되실 것입니다.\n",
    "\n",
    "또한, 이 모델들의 구조를 학습하고 이를 활용하여 우리가 네이버나 다음 영화에서 확인할 수 있는 영화리뷰에 대한 감성분석(sentiment analysis) 를 진행해보도록 하겠습니다.\n",
    "\n",
    "그럼 지금부터 시작해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-grill",
   "metadata": {},
   "source": [
    "학습 목표\n",
    "---\n",
    "- 텍스트 데이터를 머신러닝 입출력용 수치데이터로 변환하는 과정을 이해한다.\n",
    "- RNN의 특징을 이해하고 시퀀셜한 데이터를 다루는 방법을 이해한다.\n",
    "- 1-D CNN으로도 텍스트를 처리할 수 있음을 이해한다.\n",
    "- IMDB와 네이버 영화리뷰 데이터셋을 이용한 영화리뷰 감성분류 실습을 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-ultimate",
   "metadata": {},
   "source": [
    "# 7-2. 텍스트 감정분석의 유용성\n",
    "\n",
    "오늘 우리는 딥러닝을 통해 텍스트에 담긴 감성을 분석(Sentimental Analysis)하는 방법을 배워 볼 것입니다. 구체적으로는 IMDb나 네이버 영화 리뷰 텍스트에 담긴 이용자의 감성이 긍정적인지 혹은 부정적인지를 분류(Classification)할 수 있는 딥러닝 모델을 만들어 볼 것입니다.\n",
    "\n",
    "---\n",
    "그런데 딥러닝을 이용한 텍스트 감성분석은 어떤 점에서 유용할까요? 이 막연한 질문을 좀 더 세부적인 질문으로 잘게 쪼개면 다음과 같은 질문들로 나눠볼 수 있을 것입니다.\n",
    "\n",
    "- 텍스트 데이터만이 가지고 있는 정보적 특성과 가치는 어떤 것일까요?\n",
    "- 감성분석 등 텍스트 분류 모델이 다른 데이터 분석 업무에 어떤 점에서 도움을 주나요?\n",
    "- 텍스트 데이터 분석의 기술적 어려움은 무엇인가요?\n",
    "- 텍스트 분류 작업을 하는데 딥러닝이 적용되면 어떤 점에서 유리해질까요?\n",
    "\n",
    "이 질문들에 답을 제공하는 유용한 아티클 하나를 소개하겠습니다.  \n",
    "이 아티클을 정독하시면서 위 질문들에 대한 답을 찾아서 스스로 정리해 보시기 바랍니다.  \n",
    "하지만 정답이 있는 것은 아닙니다.  \n",
    "이 아티클을 통해 산업 현장에서 텍스트 분류가 실제로 활용되는 구체적인 사례도 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-retailer",
   "metadata": {},
   "source": [
    "https://dbr.donga.com/article/view/1202/article_no/8891/ac/magazine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-colonial",
   "metadata": {},
   "source": [
    "### Q1. 텍스트 데이터에서만 얻을 수 있는 유용한 정보는 무엇인가요? 그 유용성은 텍스트 데이터의 어떤 특징으로부터 비롯되는 것인가요?\n",
    "\n",
    "SNS 등에서 광범위한 분량의 텍스트 데이터를 쉽게 얻을 수 있는데, 이 데이터는 소비자들의 개인적, 감성적 반응이 직접 담겨 있을뿐더러 실시간 트렌드를 빠르게 반영하는 데이터이기도 하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-potential",
   "metadata": {},
   "source": [
    "### Q2. 텍스트 감성분석 접근법을 크게 2가지로 나누면 무엇과 무엇이 있나요?\n",
    "\n",
    "기계학습 기반 접근법과 감성사전 기반 접근법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-cigarette",
   "metadata": {},
   "source": [
    "### Q3. 사전 기반의 감성분석이 기계학습 기반 접근법 대비 가지는 한계점을 2가지만 들어 주세요.\n",
    "\n",
    "1. 분석 대상에 따라 단어의 감성 점수가 달라질 수 있다는 가능성에 대응하기 어렵다.  \n",
    "2. 단순 긍부정을 넘어서 긍부정의 원인이 되는 대상 속성 기반의 감성 분석이 어렵다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-developer",
   "metadata": {},
   "source": [
    "### Q4. 감성분석 등 텍스트 분류 모델이 다른 데이터분석 업무에 어떤 도움을 줄 수 있나요?\n",
    "\n",
    "일반적인 데이터분석 업무는 범주화가 잘 된 정형데이터를 필요로 하는데, 이런 데이터를 큰 규모로 구축하기 위해서 많은 비용이 들지만, 쉽게 구할 수 있는 비정형데이터인 텍스트에 감성분석 기법을 적용하면 텍스트를 정형데이터로 가공하여 유용한 의사결정 보조자료로 활용할 수 있게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-burden",
   "metadata": {},
   "source": [
    "### Q5. 라벨링 비용이 많이 드는 머신러닝 기반 감성분석의 비용을 절감하면서 정확도를 크게 향상시킬 수 있는 자연어처리 기법에는 무엇이 있나요?\n",
    "\n",
    "단어의 특성을 저차원 벡터값으로 표현할 수 있는 워드 임베딩(word embedding) 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-holocaust",
   "metadata": {},
   "source": [
    "# 7-3. 텍스트 데이터의 특징\n",
    "\n",
    "인공지능 모델을 입력과 출력이 정해진 함수라고 생각해 봅시다. 예를 들어 MNIST 숫자 분류기 모델이라면 이미지 파일을 읽어 들인 매트릭스가 입력이 되고, 이미지 파일에 쓰여 있는 실제 숫자 값이 출력이 되는 함수가 될 것입니다.\n",
    "\n",
    "이제 텍스트 문장을 입력으로 받아서 그 의미가 긍정이면 1, 부정이면 0을 출력하는 인공지능 모델을 만든다고 생각해 봅시다. 이 모델을 만들기 위해서는 숫자 분류기를 만들 때는 생각할 필요가 없었던 2가지 문제가 생깁니다.\n",
    "\n",
    "- 텍스트를 어떻게 숫자 행렬로 표현할 수 있나요?\n",
    "- 텍스트에는 순서가 중요합니다. 입력 데이터의 순서를 인공지능 모델에 어떻게 반영해야 하나요?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-outdoors",
   "metadata": {},
   "source": [
    "# 7-4. 텍스트 데이터의 특징 (1) 텍스트를 숫자로 표현하는 방법\n",
    "\n",
    "인공지능 모델의 입력이 될 수 있는 것은 0과 1의 비트로 표현 가능한 숫자만으로 이루어진 매트릭스일뿐입니다.\n",
    "\n",
    "아주 단순히, A=0, B=1, ..., Z=25 라고 숫자를 임의로 부여한다고 해봅시다.  \n",
    "그러면 의미적으로 A와 B는 1만큼 멀고, A와 Z는 25만큼 멀까요? 그렇지 않습니다. 텍스트의 중요한 특징은 그 자체로는 기호일 뿐이며, 텍스트가 내포하는 의미를 기호가 직접 내포하지 않는다는 점입니다.\n",
    "\n",
    "하지만 우리는 우선 단어 사전을 만들어 볼 수는 있습니다. 우리가 사용하는 국어, 영어 사전에는 단어와 그 의미 설명이 짝지어져 있습니다.\n",
    "\n",
    "우리가 하려는 것은 단어와 그 '단어의 의미를 나타내는 벡터'를 짝지어 보려고 하는 것입니다. 그런데 그 벡터는 어디서 가져올까요? 그렇습니다. 우리는 딥러닝을 통해 그 벡터를 만들어 낼 수 있습니다.\n",
    "\n",
    "아래와 같이 단 3개의 짧은 문장으로 이루어진 텍스트 데이터를 처리하는 간단한 예제를 생각해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-essex",
   "metadata": {},
   "source": [
    "i feel hungry  \n",
    "i eat lunch  \n",
    "now i feel happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "geological-argument",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 보았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "threaded-trauma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={} # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-sheep",
   "metadata": {},
   "source": [
    "단어 10개짜리 작은 딕셔너리가 만들어졌습니다. 하지만 우리가 가진 텍스트 데이터를 숫자로 바꿔 보려고 하는데, 텍스트를 숫자로 바꾸려면 위의 딕셔너리가 {텍스트:인덱스} 구조여야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "blind-fleet",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-creation",
   "metadata": {},
   "source": [
    "이 딕셔너리는 단어를 주면 그 단어의 인덱스를 반환하는 방식으로 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bright-kitchen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel']) # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-revision",
   "metadata": {},
   "source": [
    "이제 우리가 가진 텍스트 데이터를 숫자로 바꿔 표현해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "appropriate-filing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-austria",
   "metadata": {},
   "source": [
    "get_encoded_sentence 함수를 통해 아래와 같이 맵핑된 것이 확인되시나요?\n",
    "\n",
    "- <BOS> -> 1\n",
    "- i -> 3\n",
    "- eat -> 6\n",
    "- lunch -> 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "legal-reader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "immediate-appliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "minus-fisher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-christian",
   "metadata": {},
   "source": [
    "# 7-5. 텍스트 데이터의 특징 (2) Embedding 레이어의 등장\n",
    "\n",
    "텍스트가 숫자로 변환되어 인공지능 모델의 입력으로 사용될 수 있게 되었지만, 이것으로 충분하지는 않습니다.\n",
    "'i feel hungry'가 1, 3, 4, 5 로 변환되었지만 이 벡터는 텍스트에 담긴 언어의 의미와 대응되는 벡터가 아니라 임의로 부여된 단어의 순서에 불과합니다. 우리가 하려는 것은 단어와 그 단어의 의미를 나타내는 벡터를 짝짓는 것이었습니다. 그래서 단어의 의미를 나타내는 벡터를 훈련 가능한 파라미터로 놓고 이를 딥러닝을 통해 학습해서 최적화하게 됩니다. Tensorflow, Pytorch 등의 딥러닝 프레임워크들은 이러한 의미벡터 파라미터를 구현한 Embedding 레이어를 제공합니다.\n",
    "\n",
    "[임베딩 레이어를 통해 word가 벡터화되는 과정]\n",
    "https://wikidocs.net/64779\n",
    "\n",
    "위 그림에서 word_to_index('great')는 1918입니다. 그러면 'great'라는 단어의 의미공간상의 워드 벡터(word vector)는 Lookup Table형태로 구성된 Embedding 레이어의 1919번째 벡터가 됩니다. 위 그림에서는 1.2, 0.7, 1.9, 1.5가 됩니다. Embedding 레이어를 활용하여 이전 스텝의 텍스트 데이터를 워드 벡터 텐서 형태로 다시 표현해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "meaning-synthetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-190c1be7d3f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mraw_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_encoded_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m     if any(isinstance(x, (\n\u001b[1;32m    959\u001b[0m         np_arrays.ndarray, np.ndarray, float, int)) for x in input_list):\n\u001b[0;32m--> 960\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_convert_numpy_or_python_types\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3307\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3308\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3309\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2_with_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3310\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1403\u001b[0m   \"\"\"\n\u001b[1;32m   1404\u001b[0m   return convert_to_tensor_v2(\n\u001b[0;32m-> 1405\u001b[0;31m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0m\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1413\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드 벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "optical-australian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'], # <PAD> 가 0에 맵핑되어 있다.\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frequent-excuse",
   "metadata": {},
   "source": [
    "짧은 문장 뒤쪽이 0으로 채워지는 것을 확인할 수 있습니다. <PAD> 가 0에 맵핑되어 있다는 걸 기억하세요.\n",
    "\n",
    "그러면 위에 시도했던 output = embedding(raw_inputs)을 다시 시도해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "empty-suite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.01024061 -0.02735227 -0.01060553  0.00444589]\n",
      "  [-0.00244291  0.00693585  0.04804729 -0.01805254]\n",
      "  [ 0.00833864 -0.01301948  0.02408511  0.03745017]\n",
      "  [-0.03743954  0.03842201 -0.00041861 -0.0467947 ]\n",
      "  [-0.04254181  0.03526839  0.0309494   0.00731272]]\n",
      "\n",
      " [[ 0.01024061 -0.02735227 -0.01060553  0.00444589]\n",
      "  [-0.00244291  0.00693585  0.04804729 -0.01805254]\n",
      "  [-0.02503365 -0.02213024  0.03979475  0.04460518]\n",
      "  [ 0.008811   -0.0083982  -0.00785727  0.01734472]\n",
      "  [-0.04254181  0.03526839  0.0309494   0.00731272]]\n",
      "\n",
      " [[ 0.01024061 -0.02735227 -0.01060553  0.00444589]\n",
      "  [ 0.03071265 -0.01062684  0.04568223  0.01479271]\n",
      "  [-0.00244291  0.00693585  0.04804729 -0.01805254]\n",
      "  [ 0.00833864 -0.01301948  0.02408511  0.03745017]\n",
      "  [-0.02954998  0.01808523 -0.04415343  0.044949  ]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-commander",
   "metadata": {},
   "source": [
    "### Q6. output의 shape=(3, 5, 4)에서 3, 5, 4의 의미는 각각 무엇일까요?\n",
    "\n",
    "3은 입력문장 개수, 5는 입력문장의 최대 길이, 4는 워드 벡터의 차원 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-increase",
   "metadata": {},
   "source": [
    "# 7-6. 시퀀스 데이터를 다루는 RNN\n",
    "\n",
    "텍스트 데이터를 다루는 데 주로 사용되는 딥러닝 모델은 바로 Recurrent Neural Network(RNN)입니다.  \n",
    "RNN은 시퀀스(Sequence) 형태의 데이터를 처리하기에 최적인 모델로 알려져 있습니다.\n",
    "\n",
    "텍스트 데이터도 시퀀스 데이터라는 관점으로 해석할 수 있습니다만, 시퀀스 데이터의 정의에 가장 잘 어울리는 것은 음성 데이터가 아닐까 합니다. 시퀀스 데이터란 바로 입력이 시간축을 따라 발생하는 데이터입니다. 예를 들어 이전 스텝의 'i feel hungry'라는 문장을 누군가가 초당 한 단어씩, 3초에 걸쳐 이 문장을 발음했다고 합시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-video",
   "metadata": {},
   "source": [
    "at time=0s : 듣는이의 귀에 들어온 input='i'  \n",
    "at time=1s : 듣는이의 귀에 들어온 input='feel'  \n",
    "at time=2s : 듣는이의 귀에 들어온 input='hungry'  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-choice",
   "metadata": {},
   "source": [
    "time=1s인 시점에서 입력으로 받은 문장은 'i feel' 까지입니다. 그다음에 'hungry'가 올지, 'happy'가 올지 알 수 없는 상황입니다. RNN은 그런 상황을 묘사하기에 가장 적당한 모델 구조를 가지고 있습니다. 왜냐하면 RNN은 시간의 흐름에 따라 새롭게 들어오는 입력에 따라 변하는 현재 상태를 묘사하는 state machine으로 설계되었기 때문입니다.\n",
    "\n",
    "State가 무엇인지 이해를 돕기 위해 다음 그림을 보면서 질문에 대답해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-permission",
   "metadata": {},
   "source": [
    "### Q7. 위 그림에서 대화가 stateful한지 stateless한지 결정하는 것은 직원인가요, 아니면 손님인가요? 그렇게 생각하는 이유는 무엇인가요?\n",
    "\n",
    "Stateful한 대화에서는 손님이 이전 시점에 어떤 선택을 했는지 직원이 기억을 하지만, Stateless한 대화에서는 직원이 기억하지 못한다. 그래서 손님 스스로 본인이 이전 시점에 했던 선택을 모두 기억하고 있다가 직원에게 매번 새롭게 전달해야 한다. 손님의 이전 주문내역을 기억하는 직원은 stateful하고, 그렇지 못한 직원은 stateless하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-territory",
   "metadata": {},
   "source": [
    "Q8. RNN의 정의대로라면 t=4 시점의 state h4는 t=4 시점의 input x4와 t=3 시점의 state h3가 결정합니다. 그렇다면 h4에는 t<4 이전의 입력 x1, x2, x3의 정보는 반영되지 않는 것일까요?\n",
    "\n",
    "그렇지 않습니다. h4를 결정하는 이전 state h3 안에 x3의 정보가 반영되어 있고, 같은 원리로 이전 시점의 모든 입력의 정보가 현재 상태에 반영될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "literary-japanese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN 모델을 사용하여 이전 스텝의 텍스트 데이터를 처리하는 예제코드를 구현\n",
    "\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-target",
   "metadata": {},
   "source": [
    "# 7-7. 꼭 RNN이어야 할까?\n",
    "\n",
    "텍스트를 처리하기 위해 RNN이 아니라 1-D Convolution Neural Network(1-D CNN)를 사용할 수도 있습니다.  \n",
    "우리는 이미지 분류기를 구현하면서 2-D CNN을 이미 사용해 본 바 있습니다. 이미지는 시퀀스 데이터가 아닙니다. 이미지 분류기 모델에는 이미지 전체가 한꺼번에 입력으로 사용됩니다.\n",
    "\n",
    "그러므로 1-D CNN은 문장 전체를 한꺼번에 한 방향으로 길이 7짜리 필터로 스캐닝 하면서 7단어 이내에서 발견되는 특징을 추출하여 그것으로 문장을 분류하는 방식으로 사용됩니다. 이 방식도 텍스트를 처리하는 데 RNN 못지않은 효율을 보여줍니다.  \n",
    "그리고 CNN 계열은 RNN 계열보다 병렬처리가 효율적이기 때문에 학습 속도도 훨씬 빠르게 진행된다는 장점이 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "traditional-building",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-professor",
   "metadata": {},
   "source": [
    "아주 간단히는 GlobalMaxPooling1D() 레이어 하나만 사용하는 방법도 생각해 볼 수 있습니다.\n",
    "\n",
    "이 방식은 전체 문장 중에서 단 하나의 가장 중요한 단어만 피처로 추출하여 그것으로 문장의 긍정/부정을 평가하는 방식이라고 생각할 수 있는데, 의외로 성능이 잘 나올 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "confirmed-collection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-nightmare",
   "metadata": {},
   "source": [
    "이 외에도 1-D CNN과 RNN 레이어를 섞어 쓴다거나, FFN(FeedForward Network) 레이어만으로 구성하거나,  \n",
    "혹은 최근 각광받고 있는 Transformer 레이어를 쓰는 등 매우 다양한 시도를 해볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-listing",
   "metadata": {},
   "source": [
    "# 7-8. IMDb 영화리뷰 감성분석 (1) IMDB 데이터셋 분석\n",
    "\n",
    "이제 본격적으로 IMDb 영화리뷰 감성분석 태스크에 도전해 보겠습니다. IMDb Large Movie Dataset은 50000개의 영어로 작성된 영화 리뷰 텍스트로 구성되어 있으며, 긍정은 1, 부정은 0의 라벨이 달려 있습니다. 2011년 Learning Word Vectors for Sentiment Analysis 논문에서 이 데이터셋을 소개하였습니다.\n",
    "\n",
    "50000개의 리뷰 중 절반인 25000개가 훈련용 데이터, 나머지 25000개를 테스트용 데이터로 사용하도록 지정되어 있습니다. 이 데이터셋은 tensorflow Keras 데이터셋 안에 포함되어 있어서 손쉽게 다운로드하여 사용할 수 있습니다.\n",
    "\n",
    "이후 스텝의 IMDb 데이터셋 처리 코드 중 일부는 Tensorflow 튜토리얼에 언급된 데이터 전처리 로직을 참고하였음을 밝힙니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "greatest-military",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-operator",
   "metadata": {},
   "source": [
    "imdb.load_data() 호출 시 단어사전에 등재할 단어의 개수(num_words)를 10000으로 지정하면,\n",
    "\n",
    "그 개수만큼의 word_to_index 딕셔너리까지 생성된 형태로 데이터셋이 생성됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daily-nirvana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "# 다운 받은 데이터 실제 예시 확인\n",
    "\n",
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-tragedy",
   "metadata": {},
   "source": [
    "텍스트 데이터가 아니라 이미 숫자로 encode된 텍스트 데이터를 다운로드받았음을 확인할 수 있습니다.  \n",
    "이미 텍스트가 encode되었으므로 IMDb 데이터셋에는 encode에 사용한 딕셔너리까지 함께 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "recorded-transcription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-saturn",
   "metadata": {},
   "source": [
    "IMDb 데이터셋의 텍스트 인코딩을 위한 word_to_index, index_to_word는 아래와 같이 보정되어야 합니다.\n",
    "\n",
    "아래 내용은 Tensorflow 튜토리얼의 가이드를 반영하여 작성하였습니다.\n",
    "\n",
    "word_to_index는 IMDb 텍스트 데이터셋의 단어 출현 빈도 기준으로 내림차수 정렬되어 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "normal-principal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "qualified-positive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "#encode된 텍스트가 정상적으로 decode되는지 확인\n",
    "\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-palmer",
   "metadata": {},
   "source": [
    "pad_sequences를 통해 데이터셋 상의 문장의 길이를 통일하는 것을 잊어서는 안됩니다.  \n",
    "문장 최대 길이 maxlen의 값 설정도 전체 모델 성능에 영향을 미치게 됩니다.  \n",
    "이 길이도 적절한 값을 찾기 위해서는 전체 데이터셋의 분포를 확인해 보는 것이 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "funny-butler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-boundary",
   "metadata": {},
   "source": [
    "위의 경우에는 maxlen=580이 됩니다.  \n",
    "또 한가지 유의해야 하는 것은 padding 방식을 문장 뒤쪽('post')과 앞쪽('pre') 중 어느쪽으로 하느냐에 따라  \n",
    "RNN을 이용한 딥러닝 적용 시 성능 차이가 발생한다는 점입니다.  \n",
    "두 가지 방식을 한번씩 다 적용해서 RNN을 학습시켜 보면서 그 결과를 비교해 보시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "technical-guatemala",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-giant",
   "metadata": {},
   "source": [
    "### Q9. RNN 활용 시 pad_sequences의 padding 방식은 'post'와 'pre' 중 어느 것이 유리할까요? 그 이유는 무엇일까요?\n",
    "\n",
    "RNN은 입력데이터가 순차적으로 처리되어, 가장 마지막 입력이 최종 state 값에 가장 영향을 많이 미치게 됩니다. 그러므로 마지막 입력이 무의미한 padding으로 채워지는 것은 비효율적입니다. 따라서 'pre'가 훨씬 유리하며, 10% 이상의 테스트 성능 차이를 보이게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-probe",
   "metadata": {},
   "source": [
    "# 7-9. IMDb 영화리뷰 감성분석 (2) 딥러닝 모델 설계와 훈련\n",
    "\n",
    "RNN 모델을 직접 설계해 보겠습니다. 이전 스텝의 실습 내용을 참고해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "hundred-encoding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = keras.Sequential()\n",
    "# [[YOUR CODE]]\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-intro",
   "metadata": {},
   "source": [
    "model 훈련 전에, 훈련용 데이터셋 25000건 중 10000건을 분리하여 검증셋(validation set)으로 사용하도록 합니다.  \n",
    "적절한 validation 데이터는 몇 개가 좋을지 고민해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "downtown-heaven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "julian-knowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 6s 116ms/step - loss: 0.6933 - accuracy: 0.4963 - val_loss: 0.6932 - val_accuracy: 0.5017\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.6929 - accuracy: 0.5162 - val_loss: 0.6931 - val_accuracy: 0.5047\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.6923 - accuracy: 0.5147 - val_loss: 0.6929 - val_accuracy: 0.5048\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.6905 - accuracy: 0.5233 - val_loss: 0.6913 - val_accuracy: 0.5061\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.6840 - accuracy: 0.5339 - val_loss: 0.6855 - val_accuracy: 0.5162\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.6612 - accuracy: 0.5653 - val_loss: 0.6542 - val_accuracy: 0.7148\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.6001 - accuracy: 0.7125 - val_loss: 0.5787 - val_accuracy: 0.7340\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.6070 - accuracy: 0.6987 - val_loss: 0.8652 - val_accuracy: 0.5220\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.7964 - accuracy: 0.5185 - val_loss: 0.7181 - val_accuracy: 0.5042\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.6944 - accuracy: 0.5275 - val_loss: 0.6919 - val_accuracy: 0.5076\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.6800 - accuracy: 0.5331 - val_loss: 0.6890 - val_accuracy: 0.5098\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.6777 - accuracy: 0.5294 - val_loss: 0.6876 - val_accuracy: 0.5111\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.6742 - accuracy: 0.5374 - val_loss: 0.6866 - val_accuracy: 0.5123\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 3s 98ms/step - loss: 0.6730 - accuracy: 0.5345 - val_loss: 0.6861 - val_accuracy: 0.5127\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 3s 98ms/step - loss: 0.6702 - accuracy: 0.5369 - val_loss: 0.6855 - val_accuracy: 0.5124\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.6679 - accuracy: 0.5355 - val_loss: 0.6851 - val_accuracy: 0.5128\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 3s 103ms/step - loss: 0.6692 - accuracy: 0.5313 - val_loss: 0.6847 - val_accuracy: 0.5130\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 3s 101ms/step - loss: 0.6657 - accuracy: 0.5416 - val_loss: 0.6846 - val_accuracy: 0.5130\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 3s 102ms/step - loss: 0.6647 - accuracy: 0.5380 - val_loss: 0.6846 - val_accuracy: 0.5130\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 3s 104ms/step - loss: 0.6628 - accuracy: 0.5377 - val_loss: 0.6846 - val_accuracy: 0.5135\n"
     ]
    }
   ],
   "source": [
    "# model 학습\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efficient-cause",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 19s - loss: 0.6839 - accuracy: 0.5162\n",
      "[0.6839296817779541, 0.5162000060081482]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-replica",
   "metadata": {},
   "source": [
    "model.fit() 과정 중의 train/validation loss, accuracy 등이 매 epoch마다 history 변수에 저장되어 있습니다.\n",
    "\n",
    "이 데이터를 그래프로 그려 보면, 수행했던 딥러닝 학습이 잘 진행되었는지, 오버피팅 혹은 언더피팅하지 않았는지,  \n",
    "성능을 개선할 수 있는 다양한 아이디어를 얻을 수 있는 좋은 자료가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "composite-escape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "brave-filename",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyVklEQVR4nO3deZxU1Zn/8c9DgyACymZUlgYTtFFBlkajRIPZBHXAGE0kjEpM3CabJlFJNMrPhPll8TfjOKOZoIkmGRQdk2EwYjCuaMwCGDSyRVTQNmqaHWSH5/fHuQWXoqq6uqtuLd3f9+tVr7p17vZ0dXU9fc659xxzd0RERNK1K3cAIiJSmZQgREQkIyUIERHJSAlCREQyUoIQEZGMlCBERCQjJQgpCTN71MwuKfa25WRmK83sYwkc183sA9Hyf5rZt/PZtgXnmWRmj7U0zhzHHWNmDcU+rpRe+3IHIJXLzDbHXnYGtgO7o9dXuPuMfI/l7uOS2La1c/cri3EcMxsAvA50cPdd0bFnAHn/DqXtUYKQrNy9S2rZzFYCX3D3x9O3M7P2qS8dEWk91MQkzZZqQjCz683sHeAeM+tuZr82s0YzWxct943t87SZfSFanmxmz5nZrdG2r5vZuBZuO9DM5pnZJjN73MzuMLP/yhJ3PjF+x8x+Fx3vMTPrFVt/kZmtMrM1ZnZDjvfnZDN7x8xqYmWfNLOXouWTzOz3ZrbezN42s/8ws4OyHOteM/tu7PW10T5/M7NL07Y928z+bGYbzexNM5saWz0vel5vZpvN7JTUexvb/1Qzm29mG6LnU/N9b3Ixs8HR/uvNbLGZjY+tO8vMlkTHfMvMvhGV94p+P+vNbK2ZPWtm+r4qMb3h0lJHAD2AWuBywmfpnuh1f2Ar8B859j8ZWA70An4A/MTMrAXb3gf8CegJTAUuynHOfGL8LPA54HDgICD1hXUc8KPo+EdF5+tLBu7+R+A94CNpx70vWt4NXBP9PKcAHwX+KUfcRDGMjeL5ODAISO//eA+4GDgMOBu4yszOjdadHj0f5u5d3P33acfuATwC3B79bP8CPGJmPdN+hgPemyZi7gA8DDwW7fdlYIaZHRtt8hNCc2VX4ATgyaj860AD0Bt4H/AtQOMClZgShLTUHuBmd9/u7lvdfY27/9Ldt7j7JmAa8OEc+69y97vcfTfwM+BIwhdB3tuaWX9gFHCTu+9w9+eA2dlOmGeM97j7X919K/AgMCwqPx/4tbvPc/ftwLej9yCb+4GJAGbWFTgrKsPdF7r7H9x9l7uvBH6cIY5MPh3F97K7v0dIiPGf72l3/4u773H3l6Lz5XNcCAnlFXf/RRTX/cAy4B9i22R7b3L5INAF+F70O3oS+DXRewPsBI4zs27uvs7dX4iVHwnUuvtOd3/WNXBcySlBSEs1uvu21Asz62xmP46aYDYSmjQOizezpHknteDuW6LFLs3c9ihgbawM4M1sAecZ4zux5S2xmI6KHzv6gl6T7VyE2sJ5ZtYROA94wd1XRXEcEzWfvBPF8c+E2kRT9osBWJX2851sZk9FTWgbgCvzPG7q2KvSylYBfWKvs703Tcbs7vFkGj/upwjJc5WZPWNmp0TlPwRWAI+Z2WtmNiW/H0OKSQlCWir9v7mvA8cCJ7t7N/Y1aWRrNiqGt4EeZtY5VtYvx/aFxPh2/NjROXtm29jdlxC+CMexf/MShKaqZcCgKI5vtSQGQjNZ3H2EGlQ/dz8U+M/YcZv67/tvhKa3uP7AW3nE1dRx+6X1H+w9rrvPd/cJhOanWYSaCe6+yd2/7u5HA+OBr5nZRwuMRZpJCUKKpSuhTX991J59c9InjP4jXwBMNbODov8+/yHHLoXE+BBwjpl9KOpQvoWm/37uA75KSET/nRbHRmCzmdUBV+UZw4PAZDM7LkpQ6fF3JdSotpnZSYTElNJIaBI7Osux5wDHmNlnzay9mX0GOI7QHFSIPxJqG9eZWQczG0P4Hc2MfmeTzOxQd99JeE/2AJjZOWb2gaivaQOh3yZXk54kQAlCiuU24GBgNfAH4DclOu8kQkfvGuC7wAOE+zUyuY0Wxujui4EvEr703wbWETpRc0n1ATzp7qtj5d8gfHlvAu6KYs4nhkejn+FJQvPLk2mb/BNwi5ltAm4i+m882ncLoc/ld9GVQR9MO/Ya4BxCLWsNcB1wTlrczebuOwgJYRzhfb8TuNjdl0WbXASsjJrariT8PiF0wj8ObAZ+D9zp7k8VEos0n6nfR1oTM3sAWObuiddgRFo71SCkqpnZKDN7v5m1iy4DnUBoyxaRAulOaql2RwC/InQYNwBXufufyxuSSOugJiYREclITUwiIpJRq2li6tWrlw8YMKDcYYiIVJWFCxeudvfemda1mgQxYMAAFixYUO4wRESqipml30G/l5qYREQkIyUIERHJSAlCREQyajV9ECJSejt37qShoYFt27Y1vbGUVadOnejbty8dOnTIex8lCBFpsYaGBrp27cqAAQPIPt+TlJu7s2bNGhoaGhg4cGDe+6mJSURabNu2bfTs2VPJocKZGT179mx2TU8JQkQKouRQHVrye1KCkKr3yCOwcmW5oxBpfZQgpKq5w/nnw//9v+WORMphzZo1DBs2jGHDhnHEEUfQp0+fva937NiRc98FCxbwla98pclznHrqqUWJ9emnn+acc84pyrFKRZ3UUtU2bYJt22Dp0nJHIvmYMQNuuAHeeAP694dp02DSpKb3y6Znz54sWrQIgKlTp9KlSxe+8Y1v7F2/a9cu2rfP/DVXX19PfX19k+d4/vnnWx5glVMNQqpaY2N4VoKofDNmwOWXw6pVoea3alV4PWNGcc8zefJkrrzySk4++WSuu+46/vSnP3HKKacwfPhwTj31VJYvXw7s/x/91KlTufTSSxkzZgxHH300t99++97jdenSZe/2Y8aM4fzzz6euro5JkyaRGg17zpw51NXVMXLkSL7yla80WVNYu3Yt5557LkOHDuWDH/wgL730EgDPPPPM3hrQ8OHD2bRpE2+//Tann346w4YN44QTTuDZZ58t7huWg2oQUtVSCWL16vDo1au88Uh2N9wAW7bsX7ZlSygvpBaRSUNDA88//zw1NTVs3LiRZ599lvbt2/P444/zrW99i1/+8pcH7LNs2TKeeuopNm3axLHHHstVV111wD0Df/7zn1m8eDFHHXUUo0eP5ne/+x319fVcccUVzJs3j4EDBzJx4sQm47v55psZPnw4s2bN4sknn+Tiiy9m0aJF3Hrrrdxxxx2MHj2azZs306lTJ6ZPn86ZZ57JDTfcwO7du9mS/iYmSAlCqtrq2IzJy5crQVSyN95oXnkhLrjgAmpqagDYsGEDl1xyCa+88gpmxs6dOzPuc/bZZ9OxY0c6duzI4Ycfzrvvvkvfvn332+akk07aWzZs2DBWrlxJly5dOProo/feXzBx4kSmT5+eM77nnntub5L6yEc+wpo1a9i4cSOjR4/ma1/7GpMmTeK8886jb9++jBo1iksvvZSdO3dy7rnnMmzYsELemmZRE5NUtVQNAtTMVOn6929eeSEOOeSQvcvf/va3OeOMM3j55Zd5+OGHs94L0LFjx73LNTU17Nq1q0XbFGLKlCncfffdbN26ldGjR7Ns2TJOP/105s2bR58+fZg8eTI///nPi3rOXJQgpKqlEkT79rBsWXljkdymTYPOnfcv69w5lCdpw4YN9OnTB4B777236Mc/9thjee2111gZXWv9wAMPNLnPaaedxoyo8+Xpp5+mV69edOvWjVdffZUhQ4Zw/fXXM2rUKJYtW8aqVat43/vex2WXXcYXvvAFXnjhhaL/DNkoQUhVa2yEjh3huONUg6h0kybB9OlQWwtm4Xn69OL3P6S77rrr+OY3v8nw4cOL/h8/wMEHH8ydd97J2LFjGTlyJF27duXQQw/Nuc/UqVNZuHAhQ4cOZcqUKfzsZz8D4LbbbuOEE05g6NChdOjQgXHjxvH0009z4oknMnz4cB544AG++tWvFv1nyCbROanNbCzwb0ANcLe7fy9tfX/gZ8Bh0TZT3H2OmQ0AlgLLo03/4O5X5jpXfX29a8Kgtudzn4PHH4fRo2H+fHj11XJH1LYsXbqUwYMHlzuMstu8eTNdunTB3fniF7/IoEGDuOaaa8od1gEy/b7MbKG7Z7zeN7EahJnVAHcA44DjgIlmdlzaZjcCD7r7cOBC4M7YulfdfVj0yJkcpO1qbITevWHwYHj99XBPhEip3XXXXQwbNozjjz+eDRs2cMUVV5Q7pKJI8iqmk4AV7v4agJnNBCYAS2LbONAtWj4U+FuC8UgrlEoQdXXh2vq//hWGDi13VNLWXHPNNRVZYyhUkn0QfYA3Y68borK4qcA/mlkDMAf4cmzdQDP7s5k9Y2anZTqBmV1uZgvMbEFj/HIWaTMaG8OlrXV14bU6qkWKp9yd1BOBe929L3AW8Aszawe8DfSPmp6+BtxnZt3Sd3b36e5e7+71vXv3LmngUhlWrw41iGOOCR2f6qgWKZ4kE8RbQL/Y675RWdzngQcB3P33QCegl7tvd/c1UflC4FXgmARjlSq0fXsYi6l3bzj4YBgwQDUIkWJKMkHMBwaZ2UAzO4jQCT07bZs3gI8CmNlgQoJoNLPeUSc3ZnY0MAh4LcFYpQqlWhVTlcfBg5UgRIopsQTh7ruALwFzCZesPujui83sFjMbH232deAyM3sRuB+Y7OG629OBl8xsEfAQcKW7r00qVqlOqQSRGl6jri4Mt7FnT/liktI644wzmDt37n5lt912G1dddVXWfcaMGUPqkvizzjqL9evXH7DN1KlTufXWW3Oee9asWSxZsu+am5tuuonHH3+8GdFnVknDgic6FpO7zyF0PsfLbootLwFGZ9jvl8CBo2mJxKTGYUrVIOrqYOvWMLbPgAFlC0tKaOLEicycOZMzzzxzb9nMmTP5wQ9+kNf+c+bMaXqjLGbNmsU555zDcceFq/dvueWWFh+rUpW7k1qkxTI1MYE6qtuS888/n0ceeWTv5EArV67kb3/7G6eddhpXXXUV9fX1HH/88dx8880Z9x8wYACro/80pk2bxjHHHMOHPvShvUOCQ7jHYdSoUZx44ol86lOfYsuWLTz//PPMnj2ba6+9lmHDhvHqq68yefJkHnroIQCeeOIJhg8fzpAhQ7j00kvZvn373vPdfPPNjBgxgiFDhrCsiTbRcg8LrtFcpWqlJ4j4pa7jxpUnprbs6qshmrunaIYNg9tuy76+R48enHTSSTz66KNMmDCBmTNn8ulPfxozY9q0afTo0YPdu3fz0Y9+lJdeeomhWW6SWbhwITNnzmTRokXs2rWLESNGMHLkSADOO+88LrvsMgBuvPFGfvKTn/DlL3+Z8ePHc84553D++efvd6xt27YxefJknnjiCY455hguvvhifvSjH3H11VcD0KtXL1544QXuvPNObr31Vu6+++6sP1+5hwVXDUKqVmMjtGsH3buH1716hYc6qtuWVDMThOal1HwMDz74ICNGjGD48OEsXrx4v/6CdM8++yyf/OQn6dy5M926dWP8+PF717388sucdtppDBkyhBkzZrB48eKc8SxfvpyBAwdyzDHhwstLLrmEefPm7V1/3nnnATBy5Mi9A/xl89xzz3HRRRcBmYcFv/3221m/fj3t27dn1KhR3HPPPUydOpW//OUvdO3aNeex86EahFSt1auhZ8+QJFLq6tTEVC65/tNP0oQJE7jmmmt44YUX2LJlCyNHjuT111/n1ltvZf78+XTv3p3JkydnHea7KZMnT2bWrFmceOKJ3HvvvTz99NMFxZsaMryQ4cKnTJnC2WefzZw5cxg9ejRz587dOyz4I488wuTJk/na177GxRdfXFCsqkFI1UoNsxFXV6caRFvTpUsXzjjjDC699NK9tYeNGzdyyCGHcOihh/Luu+/y6KOP5jzG6aefzqxZs9i6dSubNm3i4Ycf3rtu06ZNHHnkkezcuXPvEN0AXbt2ZdOmTQcc69hjj2XlypWsWLECgF/84hd8+MMfbtHPVu5hwVWDkKqVKUEMHgx33w1r1oTahbQNEydO5JOf/OTepqbU8Nh1dXX069eP0aMPuFhyPyNGjOAzn/kMJ554IocffjijRo3au+473/kOJ598Mr179+bkk0/emxQuvPBCLrvsMm6//fa9ndMAnTp14p577uGCCy5g165djBo1iiuvbNl4o6m5socOHUrnzp33Gxb8qaeeol27dhx//PGMGzeOmTNn8sMf/pAOHTrQpUuXokwslOhw36Wk4b7bnsGD4fjjIfa3yZw5cPbZ8NxzYQhwSZaG+64uFTPct0jSUuMwxaU++2pmEimcEoRUpd27QzNSeoLo3x86dVJHtUgxKEFIVVq7Nsz/kJ4gamrCyK6qQZROa2mmbu1a8ntSgpCqlD4OU9zgwapBlEqnTp1Ys2aNkkSFc3fWrFlDp06dmrWfrmKSqpQ+DlNcXR08+GCYfrSZfw/STH379qWhoQFN2FX5OnXqRN++fZu1jxKEVKX0YTbiBg8OzU+vvAJDhpQ2rramQ4cODBw4sNxhSELUxCRVKVeCSI3JpGYmkcIoQUhVSiWITDfDpaYfVUe1SGGUIKQqrV4N3bpBNKzNflLTj6oGIVIYJQipSpmG2YjTmEwihVOCkKrU2Jj5EteUwYM1/ahIoZQgpCrlU4NITT8qIi2jBCFVKdM4THHx2eVEpGWUIKTquDddg9D81CKFU4KQqrNpE+zYkbsPolevcAmsahAiLacEIVUn101ycYMHK0GIFEIJQqpOrnGY4jQ/tUhhlCCk6uRbg6irC9uuWZN8TCKtUaIJwszGmtlyM1thZlMyrO9vZk+Z2Z/N7CUzOyu27pvRfsvN7Mwk45Tqkmuo7zjNLidSmMQShJnVAHcA44DjgIlmdlzaZjcCD7r7cOBC4M5o3+Oi18cDY4E7o+OJNKuJCZQgRFoqyRrEScAKd3/N3XcAM4EJads40C1aPhT4W7Q8AZjp7tvd/XVgRXQ8ERobwxhMXbrk3q62NswHoQQh0jJJJog+wJux1w1RWdxU4B/NrAGYA3y5GftiZpeb2QIzW6AJS9qO1D0QZrm3S00/qo5qkZYpdyf1ROBed+8LnAX8wszyjsndp7t7vbvX926qvUFajabGYYrTpa4iLZdkgngL6Bd73Tcqi/s88CCAu/8e6AT0ynNfaaOaGmYjrq4OXn89TD8qIs2TZIKYDwwys4FmdhCh03l22jZvAB8FMLPBhATRGG13oZl1NLOBwCDgTwnGKlWkqWE24urqwoiur7ySbEwirVFiCcLddwFfAuYCSwlXKy02s1vMbHy02deBy8zsReB+YLIHiwk1iyXAb4AvuvvupGKV6tKcBKFLXUVarn2SB3f3OYTO53jZTbHlJcDoLPtOA6YlGZ9Un+3bw1hM+fZBpKYfVUe1SPOVu5NapFnyvQciJTX9qGoQIs2nBCFVJd9hNuI0JpNIyyhBSFVpaYLQ9KMizacEIVUl33GY4gYPDtOPvvlm09uKyD5KEFJVmtsHAfvGZFIzk0jzKEFIVWlshHbtoEeP/PfRpa4iLaMEIVWlsTFMJdquGZ/c1PSjqkGINI8ShFSV5ozDFFdXpxqESHMpQUhVac44THEatE+k+ZQgpKo0Z5iNuLo6+PvfYe3a4sck0lopQUhVaWmCUEe1SPMpQUjV2L0b1qxpeR8EqKNapDmUIKRqrFsH7i2rQdTWhmlKVYMQyZ8ShFSNlgyzkVJTA8ceqxqESHMoQUjVKCRBgC51FWkuJQipGi0Zhylu8GBNPyrSHEoQUjVaMg5TnKYfFWkeJQipGoXWIFJXMqmZSSQ/ShBSNRoboVu3cDVSS2j6UZHmUYKQqtHScZhSOncOl7uqBiGSHyUIqRotHYcpLn1MphkzwpzV7dqF5xkzCju+SGuiBCFVo6XDbMSlLnXdsyckg8svh1Wrwg14q1aF10oSIoEShFSNYiWI1PSjN9wAW7bsv37LllAuIkoQUiXcC++DgH2D9i1dCm+8kXmbbOUibY0ShFSFzZthx47i1CAgNDP17595m2zlIm2NEoRUhUKH2Ujp3TtMP7psGUybFq5siuvcOZSLSMIJwszGmtlyM1thZlMyrP9XM1sUPf5qZutj63bH1s1OMk6pfMVKEBBqEUuXwqRJMH16uPTVLDxPnx7KRQTaJ3VgM6sB7gA+DjQA881strsvSW3j7tfEtv8yMDx2iK3uPiyp+KS6FHoXdVxdHTz8cFieNEkJQSSbJGsQJwEr3P01d98BzAQm5Nh+InB/gvFIFSt0HKa4wYM1/ahIPpJMEH2AN2OvG6KyA5hZLTAQeDJW3MnMFpjZH8zs3Cz7XR5ts6Ax9S+mtErFbmIC3VEt0pRK6aS+EHjI3XfHymrdvR74LHCbmb0/fSd3n+7u9e5e37sY3xxSsRobwxhMXboUfizNTy2SnyQTxFtAv9jrvlFZJheS1rzk7m9Fz68BT7N//4S0Mal7IMwKP1Zq+lEN2ieSW5IJYj4wyMwGmtlBhCRwwNVIZlYHdAd+HyvrbmYdo+VewGhgSfq+0nYUYxymlJqaMLKrahAiuSV2FZO77zKzLwFzgRrgp+6+2MxuARa4eypZXAjMdHeP7T4Y+LGZ7SEkse/Fr36StqcYw2zEDR4MCxcW73girVFiCQLA3ecAc9LKbkp7PTXDfs8DQ5KMTapLYyO8/4BeqJarq4OHHgrTj3bqVLzjirQmldJJLZJTMcZhihs8OIzoumJF8Y4p0tooQUjF274dNm0qbhNT6lJXdVSLZKcEIRWvmDfJpaSmH1VHtUh2ShBS8Yp5k1xKavpR1SBEslOCkIpXzHGY4lKzy4lIZnklCDM7xMzaRcvHmNl4M+uQbGgiQRJNTBA6qpcvD53VInKgfGsQ8whjI/UBHgMuAu5NKiiRuCSamCDUILZsCdOPisiB8k0Q5u5bgPOAO939AuD45MIS2aexEdq1g+7di3tcjckkklveCcLMTgEmAY9EZTXJhCSyv8ZG6NEjDJFRTLrUVSS3fBPE1cA3gf+Jhss4GngqsahEYoo5DlNcr14h8agGIZJZXkNtuPszwDMAUWf1anf/SpKBiaQUexymFLPQzKQEIZJZvlcx3Wdm3czsEOBlYImZXZtsaCJBUgkC9s1PLSIHyreJ6Th33wicCzxKmP3toqSCEolbvbr490CkaPpRkezyTRAdovsezgVmu/tOwHPvIlK4PXtgzZpkaxCgZiaRTPJNED8GVgKHAPOiOaQ3JhWUSMratSFJKEGIlF5eCcLdb3f3Pu5+lgergDMSjk0ksZvkUgYMCPNBPPoouOrEIvvJt5P6UDP7FzNbED3+H6E2IZKo1DAbSfVB1NTA9deHyYNuuSWZc4hUq3ybmH4KbAI+HT02AvckFZRIStI1CICbb4bJk2HqVPjJT5I7j0i1yXfK0fe7+6dir/+PmS1KIB6R/ZQiQZjB9Onw9ttwxRVw5JFw1lnJnU+kWuRbg9hqZh9KvTCz0cDWZEIS2Sepob7TdegA//3fcOKJcMEFsGBBsucTqQb5JogrgTvMbKWZrQT+A7gisahEIqtXQ9eu0LFj8ufq2hUeeQQOPxzOPhtefTX5c4pUsnyvYnrR3U8EhgJD3X048JFEIxMh2buoMzniCPjNb2DXLhg7dl8NRqQtataMcu6+MbqjGuBrCcQjsp9SJwiAY4+FX/8aGhrgH/4hzBkh0hYVMuWoFS0KkSzKkSAATjkF7r8f5s+HCy8MNQqRtqaQBKHbiiRxSY7D1JRzz4V//3d4+GH40pd0I520PTkThJltMrONGR6bgKOaOriZjTWz5Wa2wsymZFj/r2a2KHr81czWx9ZdYmavRI9LWvLDSXVzL18NIuWf/gmmTIEf/xj++Z/LF4dIOeS8D8Ldu7b0wGZWA9wBfBxoAOab2Wx3XxI7/jWx7b8MDI+WewA3A/WEmsrCaN91LY1Hqs/mzbB9e3kTBITE8NZbcOON0KdPuKlOpC0opImpKScBK9z9NXffAcwEJuTYfiJwf7R8JvBbd18bJYXfAmMTjFUqUCluksuHGdx9N3zsY3DZZTB3bnnjESmVJBNEH+DN2OuGqOwA0eiwA4Enm7OvmV2eGh+qUdcjtjpJj8PUHAcdBL/8JZxwAnzqU/DCC+WOSCR5SSaI5rgQeMjddzdnJ3ef7u717l7fu9z/ZkrRVUoNIqVbt3AjXc+eYSiO118vd0QiyUoyQbwF9Iu97huVZXIh+5qXmrtvQWbMCEM+t2sXnmfMKO3+kl2lJQiAo44KN9Lt2BFupEvVckRaoyQTxHxgkJkNNLODCElgdvpGZlYHdAd+HyueC3zCzLqbWXfgE1FZUc2YAZdfDqtWhStmVq0Kr/P9ki90/9QxlGAyK9U4TM01eDDMnh1+3+PH60Y6ab3ME7y428zOAm4DaoCfuvs0M7sFWODus6NtpgKd3H1K2r6XAt+KXk5z95zDi9fX1/uCZo6wNmBA+CNP16EDfOADoXMyxHLgs1mY7H7nzgP379gRRo0Kcw2kHu3aHfi6oQEWLoTdsYa1Dh3gkktCE0b37uHRo0d4PuSQfTGkzJgBN9wAb7wB/fvDtGkwaVKz3oaKdf31cNttsG3bgT93JfjVr+D882HChDCfRE1NuSMSaT4zW+ju9RnXJZkgSqklCaJdu+w3P51/fnhOrY8/p5Znzcp+7DPOCF/8u3eHKTNTy/HXy5c37w7dDh32JY3u3WHrVnj55f0TzMEHw113tY4kceml8NhjIZFWqksugZ//PCx37Aj19eF3P2AA1NaG5379SjPYoEhL5EoQ+c4H0Sr175+5BlFbG4Z+bkq2GkhtLTz55IHl6drlaOD785/DfMzr1oVHpuUXXtg/OUBIGldcEe4fSH1RVeJ/3/ko901yTZkxI9QcUrZvh+efD4/4Px5mYY6JVMKIJ4/a2vA4+OASBy+ShzadIKZNC30G8Tbkzp1DeSn2z5Wghg1rev9sCea99+Dzn993jjFj9j2qKWE0NlZe/0PcDTcc2P/gHt7zZ54Jv9uVK/d//uMfwz8f6TXHbt3gsMPyf3Tvvm+5W7fc/2yItFSbThCpZpiWtuEXun9SCaZ/f3j0UXjqKXj6aZgzZ18zSCphnHHGvoRRqVavhqOPLncU2b3xRubyN9/cV1P48IcPXL97d5i9Lp48Vq+G9ev3PVatghdfDMsbNuSOwyx8bg45JDxSy5nKsq3v2DHc69Ghw4HPmcri66rlHw5pvjbdB1EJCulkTl1FlZ5gpk/f/xjusGRJSBZPPRX+u43fhLZ1a6h11NZWVif3oYeGYS3+7d/KHUlmuZoYV64s3nl274ZNm/Ylj3Xr9k8m69aFYUm2bAm/x/fe27ecqWz79uLFBtC+fUgYHTvuSzSp5XzLDjooHKdDh/AcX05/zrUulbTij0zlqbKaGiU49UFUsEmTWv6FnG8NxgyOPz48vvjF0Em+ZAn88IchyaT6MVKX6caPXS7bt8PGjZXdB1FoDTBfNTX7mpOKYffuAxPI9u3h3o6dO8MjtZz+nG3djh3hGKnjpJbjZevWHViWWk4dO71PrRRSiQJyX7nY3OemyrLtm02u9SNGhEuvi00Josq1JMG0axeGjHjmmQP/ILdsCQmn3AmikobZyKbQJkYoz2XKNTVhetWuLR6KMznuoX8m9di5M/Nzeln6cnPL9uzJfMViS5+bKsu2b673JZeBA3OvbykliDYsWxt6tvJSSiWISq5BQGE1wPQmwkqqwZWL2b5mICk/XfvQhvXvn7n8iCNKG0cmlTjMRrFlugoqVYPLl+7ElyQpQbRh06aFNvN0NTXlHz6iLSSIQmtwxRjqRSQXJYg2bNKkcMVTbW2o2tfWwnXXhTuXr766vLFV6jhMxZStBpetPJ1qIJI0JYg2btKkcEnmnj3h+fvfD1Ns3nUX3H9/U3snZ/XqkLR69ChfDEnLVINrzlVQlVADUYJp3ZQg5AC33AKnnhq+LF55pTwxNDaGeRda8wB4mWpw6few5FLuGoiauFo/JQg5QIcOofbQoQN85jPFv7EqH5U+DlOxpNfgmnP1UrlrIGriav2UICSj/v3h3nvDoIHXXlv681f6OEyVoNw1EDVxtQHu3ioeI0eOdCm+q68Ot/X86lelPe9xx7mfd15pz9nW/Nd/uXfunLptKzw6dw7l+ait3X/f1KO2tjT7Fxp/6hi1te5m4bk5+7YWhPl5Mn6vlv2LvVgPJYhkbN/uXl/vfthh7itXlu68vXu7X3FF6c7XVhXyBVnoF7RZ5gRhlt/+SjDFoQQhBVmxwr1bN/cPftB9x47kz7d7t3u7du433tj0tq3hD7SaFfL+F/oFrwRTHEoQUrAHHgifluuuS/5cjY3hXLfdlnu7YvyBSvmUu4lLCSZQgpCiuPLK8ImZMyfZ8yxdGs4zY0bu7Qr9A5XyK2cTlxJMoAQhRbFli/vQoe69erk3NCR3nnnzwifzscdyb1foH6hUPyWYwv9BypUgdJmr5O3gg+GBB8IEQ5/97IHTZhZLvuMwFXqZplS/Qu4jKfQy4ULvQyn3Zcb5UIKQZqmrgx/9CObNg+98J5lz5DsOU6F/oCJtOcHkJVvVotoeamIqrcmTQ1X4iSeKf+zvfjdUlbdta3rbSrgKRKSlytlElkKOJibNSS0t8t57UF8f5kRetAje977iHfvqq+GnPw1TjopIdsWYkTDXnNRqYpIWOeQQePDBkCAuuihU0YulrYzDJFKoQprI8qEEIS02ZAjcfjv89rfw4x8X77gah0mkMiSaIMxsrJktN7MVZjYlyzafNrMlZrbYzO6Lle82s0XRY3aScUrLfeELcOKJcN99TW+br9WrVYMQqQTtkzqwmdUAdwAfBxqA+WY2292XxLYZBHwTGO3u68zs8Nghtrr7sKTik+K4775Qtd2wAfr1g+99r/BqbmNjSDoiUl5J1iBOAla4+2vuvgOYCUxI2+Yy4A53Xwfg7n9PMB4pstRwzRs2hNcNDYVPGOOuPgiRSpFkgugDvBl73RCVxR0DHGNmvzOzP5jZ2Ni6Tma2ICo/N9MJzOzyaJsFjamL56VkijFhTLrNm8MEReqDECm/xJqYmnH+QcAYoC8wz8yGuPt6oNbd3zKzo4Enzewv7v5qfGd3nw5Mh3CZa0kjl0Tu5Fy9OjyrBiFSfknWIN4C+sVe943K4hqA2e6+091fB/5KSBi4+1vR82vA08DwBGOVFkjiTs58h9kQkeQlmSDmA4PMbKCZHQRcCKRfjTSLUHvAzHoRmpxeM7PuZtYxVj4aWIJUlExDBdTUFDbUhRKESOVILEG4+y7gS8BcYCnwoLsvNrNbzGx8tNlcYI2ZLQGeAq519zXAYGCBmb0YlX8vfvWTVIb0sWg6d4YuXWDixJYfM9XEpD4IkfLTUBtSNPffH0Z5ff55OOWUlh3j1lvh2mvDlVHduhU3PhE5kIbakJIYNw7at4fZBdzW2NgIBx0EXbsWLy4RaRklCCmaww6DD38Y/vd/W36M1D0QZkULS0RaSAlCimrCBFi6FF55pWX7r16t/geRSqEEIUU1Prr8oKXNTLqLWqRyKEFIUdXWhnGUWtrMpAQhUjmUIKToJkyA3/1u3yWrzaEEIVI5lCCk6MaPDxOYPPJI8/bbsSPMIqc+CJHKoAQhRTdiBPTt2/xmJo3DJFJZlCCk6MxCLWLuXNi6Nf/9NMyGSGVRgpBEjB8fhv5+4on891GCEKksShCSiDFjwt3QzbncVeMwiVQWJQhJRMeOYeiNhx8OHdb5UA1CpLIoQUhiJkyAd96BP/0pv+0bG0P/RY8eycYlIvlRgpDEjBsX5ofIt5mpsRF69gz7iEj5KUFIYrp3b97gfRqHSaSyKEFIoiZMgCVLYMWKprfVXdQilUUJQhLVnMH7lCBEKosShCRqwAAYOjS/ZiYlCJHKogQhiZswAZ57LvfgfXv2wJo16oMQqSRKEJK41OB9c+Zk32bdurCNahAilUMJQhI3ciT06ZO7mUk3yYlUHiUISVx88L5t2zJvowQhUnmUIKQkxo+H997LPnifxmESqTxKEFISZ5yRe/A+1SBEKo8ShJREx44wdmxIEJkG71OCEKk8iSYIMxtrZsvNbIWZTcmyzafNbImZLTaz+2Lll5jZK9HjkiTjlNIYPz4M3jd//oHrGhtDDaNjx9LHJSKZtU/qwGZWA9wBfBxoAOab2Wx3XxLbZhDwTWC0u68zs8Oj8h7AzUA94MDCaN91ScUryTvrrH2D95188v7rNA6TSOVJsgZxErDC3V9z9x3ATGBC2jaXAXekvvjd/e9R+ZnAb919bbTut8DYBGOVEujRA04/PfPlrrqLWqTyJJkg+gBvxl43RGVxxwDHmNnvzOwPZja2GftiZpeb2QIzW9CYasSWijZ+PCxeDK++un+5EoRI5Sl3J3V7YBAwBpgI3GVmh+W7s7tPd/d6d6/vrW+XqjAhqkOmX82kBCFSeZJMEG8B/WKv+0ZlcQ3AbHff6e6vA38lJIx89pUqNHAgDBmyfzOTu/ogRCpRkgliPjDIzAaa2UHAhUD6VfCzCLUHzKwXocnpNWAu8Akz625m3YFPRGXSCkyYAM8+GwbnmzEDamvDHdZ33x1ei0hlSCxBuPsu4EuEL/alwIPuvtjMbjGzaJYA5gJrzGwJ8BRwrbuvcfe1wHcISWY+cEtUJq1AavC+G2+Eyy+HN6PepvXrw2slCZHKYO5e7hiKor6+3hcsWFDuMCQPe/ZAv34hIWzZcuD62lpYubLUUYm0TWa20N3rM60rdye1tEHt2oVaRKbkAPDGG6WNR0QyU4KQskhNRZpJ//6li0NEslOCkLL4yEegUydon3Yvf+fOMG1aeWISkf0pQUhZdOwI55wDXbpAt26hrH9/mD4dJk0qb2wiEiQ2FpNIU8aPh4ceghNOgLVrYdWqckckInGqQUjZnH12GLzv5Zd1F7VIJVKCkLLp0QNOOy0sK0GIVB4lCCmr1NVMGmZDpPIoQUhZpQbvUw1CpPKok1rK6uij4fvfh499rNyRiEg6JQgpu+uuK3cEIpKJmphERCQjJQgREclICUJERDJSghARkYyUIEREJCMlCBERyUgJQkREMlKCEBGRjFrNnNRm1ghU8oDRvYDV5Q4iB8VXGMVXGMVXmELiq3X3jIPdtJoEUenMbEG2icErgeIrjOIrjOIrTFLxqYlJREQyUoIQEZGMlCBKZ3q5A2iC4iuM4iuM4itMIvGpD0JERDJSDUJERDJSghARkYyUIIrEzPqZ2VNmtsTMFpvZVzNsM8bMNpjZouhxUxniXGlmf4nOvyDDejOz281shZm9ZGYjShjbsbH3ZpGZbTSzq9O2Kel7aGY/NbO/m9nLsbIeZvZbM3sleu6eZd9Lom1eMbNLShjfD81sWfT7+x8zOyzLvjk/CwnGN9XM3or9Ds/Ksu9YM1sefRanlDC+B2KxrTSzRVn2LcX7l/F7pWSfQXfXowgP4EhgRLTcFfgrcFzaNmOAX5c5zpVArxzrzwIeBQz4IPDHMsVZA7xDuImnbO8hcDowAng5VvYDYEq0PAX4fob9egCvRc/do+XuJYrvE0D7aPn7meLL57OQYHxTgW/k8ft/FTgaOAh4Mf3vKan40tb/P+CmMr5/Gb9XSvUZVA2iSNz9bXd/IVreBCwF+pQ3qhaZAPzcgz8Ah5nZkWWI46PAq+5e1rvj3X0esDateALws2j5Z8C5GXY9E/itu69193XAb4GxpYjP3R9z913Ryz8AfYt93nxlef/ycRKwwt1fc/cdwEzC+15UueIzMwM+Ddxf7PPmK8f3Skk+g0oQCTCzAcBw4I8ZVp9iZi+a2aNmdnxpIwPAgcfMbKGZXZ5hfR/gzdjrBsqT6C4k+x9mud/D97n729HyO8D7MmxTKe/jpYQaYSZNfRaS9KWoCeynWZpHKuH9Ow14191fybK+pO9f2vdKST6DShBFZmZdgF8CV7v7xrTVLxCaTE4E/h2YVeLwAD7k7iOAccAXzez0MsSQk5kdBIwH/jvD6kp4D/fyUJevyGvFzewGYBcwI8sm5fos/Ah4PzAMeJvQjFOJJpK79lCy9y/X90qSn0EliCIysw6EX+IMd/9V+np33+jum6PlOUAHM+tVyhjd/a3o+e/A/xCq8nFvAf1ir/tGZaU0DnjB3d9NX1EJ7yHwbqrZLXr+e4Ztyvo+mtlk4BxgUvQFcoA8PguJcPd33X23u+8B7spy3nK/f+2B84AHsm1Tqvcvy/dKST6DShBFErVX/gRY6u7/kmWbI6LtMLOTCO//mhLGeIiZdU0tEzozX07bbDZwsQUfBDbEqrKlkvU/t3K/h5HZQOqKkEuA/82wzVzgE2bWPWpC+URUljgzGwtcB4x39y1Ztsnns5BUfPE+rU9mOe98YJCZDYxqlBcS3vdS+RiwzN0bMq0s1fuX43ulNJ/BJHvg29ID+BChmvcSsCh6nAVcCVwZbfMlYDHhiow/AKeWOMajo3O/GMVxQ1Qej9GAOwhXkPwFqC9xjIcQvvAPjZWV7T0kJKq3gZ2ENtzPAz2BJ4BXgMeBHtG29cDdsX0vBVZEj8+VML4VhLbn1OfwP6NtjwLm5PoslCi+X0SfrZcIX3RHpscXvT6LcNXOq6WMLyq/N/WZi21bjvcv2/dKST6DGmpDREQyUhOTiIhkpAQhIiIZKUGIiEhGShAiIpKREoSIiGSkBCHSBDPbbfuPMlu0kUXNbEB8JFGRStK+3AGIVIGt7j6s3EGIlJpqECItFM0H8INoToA/mdkHovIBZvZkNBjdE2bWPyp/n4X5GV6MHqdGh6oxs7ui8f4fM7ODo+2/Es0D8JKZzSzTjyltmBKESNMOTmti+kxs3QZ3HwL8B3BbVPbvwM/cfShhoLzbo/LbgWc8DDQ4gnAHLsAg4A53Px5YD3wqKp8CDI+Oc2UyP5pIdrqTWqQJZrbZ3btkKF8JfMTdX4sGVHvH3Xua2WrC8BE7o/K33b2XmTUCfd19e+wYAwhj9g+KXl8PdHD375rZb4DNhBFrZ3k0SKFIqagGIVIYz7LcHNtjy7vZ1zd4NmFcrBHA/GiEUZGSUYIQKcxnYs+/j5afJ4w+CjAJeDZafgK4CsDMaszs0GwHNbN2QD93fwq4HjgUOKAWI5Ik/Uci0rSDbf+J63/j7qlLXbub2UuEWsDEqOzLwD1mdi3QCHwuKv8qMN3MPk+oKVxFGEk0kxrgv6IkYsDt7r6+SD+PSF7UByHSQlEfRL27ry53LCJJUBOTiIhkpBqEiIhkpBqEiIhkpAQhIiIZKUGIiEhGShAiIpKREoSIiGT0/wFV+s5snp2XLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-tribute",
   "metadata": {},
   "source": [
    "Training and validation loss를 그려 보면, 몇 epoch까지의 트레이닝이 적절한지 최적점을 추정해 볼 수 있습니다.  \n",
    "validation loss의 그래프가 train loss와의 이격이 발생하게 되면 더 이상의 트레이닝은 무의미해지게 마련입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "measured-technical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-terrace",
   "metadata": {},
   "source": [
    "# 7-10. IMDb 영화리뷰 감성분석 (3) Word2Vec의 적용\n",
    "\n",
    "이전 스텝에서 라벨링 비용이 많이 드는 머신러닝 기반 감성분석의 비용을 절감하면서 정확도를 크게 향상시킬 수 있는 자연어처리 기법으로 단어의 특성을 저차원 벡터값으로 표현할 수 있는 워드 임베딩(word embedding) 기법이 있다는 언급을 한 바 있습니다.\n",
    "\n",
    "우리는 이미 이전 스텝에서 워드 임베딩을 사용했습니다. 사용했던 model의 첫 번째 레이어는 바로 Embedding 레이어였습니다. 이 레이어는 우리가 가진 사전의 단어 개수 X 워드 벡터 사이즈만큼의 크기를 가진 학습 파라미터였습니다. 만약 우리의 감성분류 모델이 학습이 잘 되었다면, Embedding 레이어에 학습된 우리의 워드 벡터들도 의미 공간상에 유의미한 형태로 학습되었을 것입니다. 한번 확인해 봅시다.\n",
    "\n",
    "이번 스텝부터 워드 벡터 파일을 저장할 디렉토리를 먼저 생성합시다. 그리고 워드 벡터를 다루는데 유용한 gensim 패키지 버전 확인을 합니다.\n",
    "\n",
    "Cloud shell에서 아래 명령어를 입력해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "optimum-lancaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "lined-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "derived-journalism",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.05772187, -0.03303562,  0.04033623, -0.01508293,  0.04807699,\n",
       "       -0.08402092, -0.06686901, -0.02337188, -0.03505178,  0.02155765,\n",
       "        0.06381966, -0.00949069,  0.04418985,  0.08787023, -0.08468424,\n",
       "        0.02339565], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gensim에서 제공하는 패키지를 이용해, 위에 남긴 임베딩 파라미터를 읽어서 word vector로 활용할 수 있습니다.\n",
    "\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "associate-arctic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rid', 0.8873472213745117),\n",
       " ('bud', 0.8836321830749512),\n",
       " ('friend', 0.8796173930168152),\n",
       " ('rare', 0.8786551356315613),\n",
       " ('studies', 0.8785526752471924),\n",
       " ('sam', 0.87407386302948),\n",
       " ('struggle', 0.8725858330726624),\n",
       " ('sons', 0.8724474310874939),\n",
       " ('indulgent', 0.8684524893760681),\n",
       " ('finding', 0.8665264844894409)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-rally",
   "metadata": {},
   "source": [
    "어떻습니까? love라는 단어와 유사한 다른 단어를 그리 잘 찾았다고 느껴지지는 않습니다. 감성분류 태스크를 잠깐 학습한 것만으로 워드 벡터가 유의미하게 학습되기는 어려운 것 같습니다. 우리가 다룬 정도의 훈련데이터로는 워드 벡터를 정교하게 학습시키기 어렵습니다.\n",
    "\n",
    "그래서 이번에는 구글에서 제공하는 Word2Vec이라는 사전학습된(Pretrained) 워드 임베딩 모델을 가져다 활용해 보겠습니다. Word2Vec은 무려 1억 개의 단어로 구성된 Google News dataset을 바탕으로 학습되었습니다. 총 300만 개의 단어를 각각 300차원의 벡터로 표현한 것입니다. Word2Vec이 학습되는 원리에 대해서는 차후 깊이있게 다루게 될 것입니다. 하지만 그렇게 해서 학습된 Word2Vec이라는 것도 실은 방금 우리가 파일에 써본 Embedding Layer와 원리는 동일합니다.\n",
    "\n",
    "임베딩의 개념에 대해 아주 잘 정리된 책 한국어 임베딩의 서론에서 왜 사전학습된 임베딩을 활용하는 것이 유리한지 설명해 주고 있습니다. 바로 전이학습 때문입니다. 관련 내용을 읽어본 후 질문에 답해 봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-bishop",
   "metadata": {},
   "source": [
    "### Q10. 사전에 학습된 Word2Vec 등의 임베딩 모델을 활용하는 전이학습(Transfer Learning)이 유리한 이유를 설명해 보세요.\n",
    "\n",
    "사람도 무언가를 배우기 위해 제로베이스에서 시작하지 않고 자신이 지닌 이전의 경험과 지식을 동원하는 것처럼, 광범위한 데이터를 통해 미리 학습해 놓은 임베딩 속에 녹아 있는 의미, 문법 등의 부가적인 정보를 내가 만들려는 모델이 활용할 수 있는 피처로 활용하는 것이 훨씬 빠르고 정확하게 학습할 수 있는 방법이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "revolutionary-designation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Google의 Word2Vec 모델을 가져와 적용\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-telescope",
   "metadata": {},
   "source": [
    "300dim의 벡터로 이루어진 300만 개의 단어입니다.  \n",
    "\n",
    "이 단어 사전을 메모리에 모두 로딩하면 아주 높은 확률로 여러분의 실습환경에 메모리 에러가 날 것입니다.  \n",
    "\n",
    "그래서 KeyedVectors.load_word2vec_format 메소드로 워드 벡터를 로딩할 때 가장 많이 사용되는 상위 100만 개만 limt으로 조건을 주어 로딩했습니다.\n",
    "\n",
    "메모리가 충분하다면 limt=None으로 하시면 300만 개를 모두 로딩합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "paperback-portland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907791495323181),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100708842277527),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547304749488831),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "creative-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "spanish-nutrition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "varied-bailey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 22s 573ms/step - loss: 0.6975 - accuracy: 0.5056 - val_loss: 0.6878 - val_accuracy: 0.5394\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 12s 386ms/step - loss: 0.6818 - accuracy: 0.5643 - val_loss: 0.6725 - val_accuracy: 0.5802\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 12s 387ms/step - loss: 0.6454 - accuracy: 0.6396 - val_loss: 0.5971 - val_accuracy: 0.6923\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 11s 386ms/step - loss: 0.5317 - accuracy: 0.7544 - val_loss: 0.4232 - val_accuracy: 0.8169\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 12s 387ms/step - loss: 0.3613 - accuracy: 0.8542 - val_loss: 0.3394 - val_accuracy: 0.8576\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 11s 385ms/step - loss: 0.2629 - accuracy: 0.8986 - val_loss: 0.3145 - val_accuracy: 0.8669\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 11s 384ms/step - loss: 0.1924 - accuracy: 0.9352 - val_loss: 0.3043 - val_accuracy: 0.8713\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 11s 385ms/step - loss: 0.1407 - accuracy: 0.9590 - val_loss: 0.3131 - val_accuracy: 0.8743\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 11s 385ms/step - loss: 0.1008 - accuracy: 0.9729 - val_loss: 0.3206 - val_accuracy: 0.8753\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 12s 389ms/step - loss: 0.0662 - accuracy: 0.9872 - val_loss: 0.3337 - val_accuracy: 0.8768\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 12s 398ms/step - loss: 0.0438 - accuracy: 0.9952 - val_loss: 0.3535 - val_accuracy: 0.8760\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 13s 431ms/step - loss: 0.0318 - accuracy: 0.9975 - val_loss: 0.3811 - val_accuracy: 0.8742\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 12s 399ms/step - loss: 0.0179 - accuracy: 0.9995 - val_loss: 0.3986 - val_accuracy: 0.8723\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 12s 398ms/step - loss: 0.0123 - accuracy: 0.9994 - val_loss: 0.4288 - val_accuracy: 0.8735\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 12s 396ms/step - loss: 0.0082 - accuracy: 0.9996 - val_loss: 0.4447 - val_accuracy: 0.8745\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 12s 398ms/step - loss: 0.0059 - accuracy: 0.9997 - val_loss: 0.4655 - val_accuracy: 0.8740\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 12s 398ms/step - loss: 0.0044 - accuracy: 0.9998 - val_loss: 0.4829 - val_accuracy: 0.8733\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 12s 397ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.8744\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 12s 399ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.5146 - val_accuracy: 0.8739\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 12s 399ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5276 - val_accuracy: 0.8738\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "informal-exchange",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 11s - loss: 0.5650 - accuracy: 0.8620\n",
      "[0.5649712681770325, 0.8620399832725525]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "convinced-domain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "hairy-navigator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "piano-information",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
